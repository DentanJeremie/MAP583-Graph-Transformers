{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pt4syj74XxU_"
   },
   "source": [
    "# Notebook for preparing and saving SBM_PATTERN graphs in DGL form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IT1_X2U2XxVD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKkhFE6VXxVE"
   },
   "source": [
    "## Download SBM_PATTERN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UjeFFxxrXxVF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading..\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   139    0   139    0     0    308      0 --:--:-- --:--:-- --:--:--   308\n",
      "100   320  100   320    0     0    349      0 --:--:-- --:--:-- --:--:--     0\n",
      " 10 55.9M   10 6144k    0     0  2232k      0  0:00:25  0:00:02  0:00:23 7718k^C\n",
      "Archive:  SBM_PATTERN.zip\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of SBM_PATTERN.zip or\n",
      "        SBM_PATTERN.zip.zip, and cannot find SBM_PATTERN.zip.ZIP, period.\n",
      "rm: cannot remove ‘__MACOSX/’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('SBM_PATTERN.zip'):\n",
    "    print('downloading..')\n",
    "    !curl https://www.dropbox.com/s/qvu0r11tjyt6jyb/SBM_PATTERN.zip?dl=1 -o SBM_PATTERN.zip -J -L -k\n",
    "    !unzip SBM_PATTERN.zip -d ./\n",
    "    !rm -r __MACOSX/\n",
    "else:\n",
    "    print('File already downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ1mkzjtXxVG"
   },
   "source": [
    "## Convert to DGL format and save with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SI4t5ozUXxVG",
    "outputId": "f4787e96-0e7c-4db8-98ea-ab362d768c6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2019/jeremie.dentan/graph_transformer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/users/eleves-b/2019/jeremie.dentan/graph_transformer') # go to root folder of the project\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zyQEmKZ4XxVI",
    "outputId": "d2aa1907-8beb-4b43-8aee-6d76f87f0ae6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data.SBMs import SBMsDatasetDGL \n",
    "\n",
    "from data.data import LoadData\n",
    "from torch.utils.data import DataLoader\n",
    "from data.SBMs import SBMsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "AYLvTnFFXxVJ"
   },
   "outputs": [],
   "source": [
    "class DotDict(dict):\n",
    "    def __init__(self, **kwds):\n",
    "        self.update(kwds)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcQj4tRzXxVJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Loading data ...\n",
      "preparing 10000 graphs for the TRAIN set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2019/jeremie.dentan/graph_transformer/data/SBMs.py:40: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  edge_list = (data.W != 0).nonzero()  # converting adj matrix to edge_list\n",
      "/users/eleves-b/2019/jeremie.dentan/miniconda3/envs/graph_transformer/lib/python3.7/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "DATASET_NAME = 'SBM_PATTERN'\n",
    "dataset = SBMsDatasetDGL(DATASET_NAME) \n",
    "\n",
    "print('Time (sec):',time.time() - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dlgPjKcXxVL",
    "outputId": "4e3dfddb-4191-4ce2-a2b0-c78e13e4ac31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "2000\n",
      "2000\n",
      "(DGLGraph(num_nodes=108, num_edges=4884,\n",
      "         ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "         edata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32)}), tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0], dtype=torch.int16))\n",
      "(DGLGraph(num_nodes=108, num_edges=4738,\n",
      "         ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "         edata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32)}), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1], dtype=torch.int16))\n",
      "(DGLGraph(num_nodes=94, num_edges=3772,\n",
      "         ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "         edata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32)}), tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       dtype=torch.int16))\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.train))\n",
    "print(len(dataset.val))\n",
    "print(len(dataset.test))\n",
    "\n",
    "print(dataset.train[0])\n",
    "print(dataset.val[0])\n",
    "print(dataset.test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7v27t6NXxVL"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with open('data/SBMs/SBM_PATTERN.pkl','wb') as f:\n",
    "        pickle.dump([dataset.train,dataset.val,dataset.test],f)\n",
    "        \n",
    "print('Time (sec):',time.time() - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-4BnoAXXxVL",
    "outputId": "90857c9d-32bb-45f1-d3de-96093de4ff91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Loading dataset SBM_PATTERN...\n",
      "train, test, val sizes : 10000 2000 2000\n",
      "[I] Finished loading.\n",
      "[I] Data load time: 22.8220s\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = 'SBM_PATTERN'\n",
    "dataset = LoadData(DATASET_NAME) \n",
    "trainset, valset, testset = dataset.train, dataset.val, dataset.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pq0Ykf19XxVM",
    "outputId": "45ef5c79-0392-4851-dc5b-6bc5f455b1ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (sec): 0.8683583736419678\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "batch_size = 10\n",
    "collate = SBMsDataset.collate\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "\n",
    "print('Time (sec):',time.time() - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nbWrftPXxVM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "prepare_SBM_PATTERN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
